{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Cubic Data (multi-dimensional)\n",
    "- y = x^3 -3x^2 -9x -1\n",
    "- 5 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from visdom import Visdom\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/_w1zc2m561d_76233frzs4qr0000gn/T/ipykernel_15833/3772392901.py:4: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
      "/var/folders/ws/_w1zc2m561d_76233frzs4qr0000gn/T/ipykernel_15833/3772392901.py:7: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  noise = init.normal(torch.FloatTensor(num_data,1),std=3)\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 5000\n",
    "\n",
    "x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "y = (x**3) - 3*(x**2) - 9*x - 1\n",
    "\n",
    "noise = init.normal(torch.FloatTensor(num_data,1),std=3)\n",
    "\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(x, y)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter((x+noise), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "input_data = torch.cat([x,y_noise],1)\n",
    "\n",
    "win=viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "win=viz.scatter(\n",
    "    X = torch.cat([x,y],1),\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(1,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,1),\n",
    "        )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(215.9405, grad_fn=<L1LossBackward0>)\n",
      "tensor(215.8835, grad_fn=<L1LossBackward0>)\n",
      "tensor(215.7777, grad_fn=<L1LossBackward0>)\n",
      "tensor(215.5607, grad_fn=<L1LossBackward0>)\n",
      "tensor(215.0391, grad_fn=<L1LossBackward0>)\n",
      "tensor(213.1969, grad_fn=<L1LossBackward0>)\n",
      "tensor(199.3727, grad_fn=<L1LossBackward0>)\n",
      "tensor(137.6155, grad_fn=<L1LossBackward0>)\n",
      "tensor(134.5334, grad_fn=<L1LossBackward0>)\n",
      "tensor(131.1724, grad_fn=<L1LossBackward0>)\n",
      "tensor(127.2196, grad_fn=<L1LossBackward0>)\n",
      "tensor(121.9333, grad_fn=<L1LossBackward0>)\n",
      "tensor(113.6448, grad_fn=<L1LossBackward0>)\n",
      "tensor(100.4025, grad_fn=<L1LossBackward0>)\n",
      "tensor(84.7289, grad_fn=<L1LossBackward0>)\n",
      "tensor(91.0946, grad_fn=<L1LossBackward0>)\n",
      "tensor(80.7711, grad_fn=<L1LossBackward0>)\n",
      "tensor(76.3647, grad_fn=<L1LossBackward0>)\n",
      "tensor(79.1123, grad_fn=<L1LossBackward0>)\n",
      "tensor(72.8752, grad_fn=<L1LossBackward0>)\n",
      "tensor(75.6689, grad_fn=<L1LossBackward0>)\n",
      "tensor(72.7844, grad_fn=<L1LossBackward0>)\n",
      "tensor(70.3355, grad_fn=<L1LossBackward0>)\n",
      "tensor(72.3334, grad_fn=<L1LossBackward0>)\n",
      "tensor(69.3206, grad_fn=<L1LossBackward0>)\n",
      "tensor(68.8479, grad_fn=<L1LossBackward0>)\n",
      "tensor(68.4954, grad_fn=<L1LossBackward0>)\n",
      "tensor(67.1500, grad_fn=<L1LossBackward0>)\n",
      "tensor(67.4957, grad_fn=<L1LossBackward0>)\n",
      "tensor(67.9894, grad_fn=<L1LossBackward0>)\n",
      "tensor(66.5309, grad_fn=<L1LossBackward0>)\n",
      "tensor(66.4279, grad_fn=<L1LossBackward0>)\n",
      "tensor(65.8076, grad_fn=<L1LossBackward0>)\n",
      "tensor(65.7101, grad_fn=<L1LossBackward0>)\n",
      "tensor(65.2529, grad_fn=<L1LossBackward0>)\n",
      "tensor(64.5885, grad_fn=<L1LossBackward0>)\n",
      "tensor(63.3626, grad_fn=<L1LossBackward0>)\n",
      "tensor(61.4534, grad_fn=<L1LossBackward0>)\n",
      "tensor(55.3926, grad_fn=<L1LossBackward0>)\n",
      "tensor(43.7943, grad_fn=<L1LossBackward0>)\n",
      "tensor(36.3981, grad_fn=<L1LossBackward0>)\n",
      "tensor(32.0970, grad_fn=<L1LossBackward0>)\n",
      "tensor(30.3038, grad_fn=<L1LossBackward0>)\n",
      "tensor(30.4817, grad_fn=<L1LossBackward0>)\n",
      "tensor(41.5853, grad_fn=<L1LossBackward0>)\n",
      "tensor(35.8255, grad_fn=<L1LossBackward0>)\n",
      "tensor(24.3101, grad_fn=<L1LossBackward0>)\n",
      "tensor(26.3483, grad_fn=<L1LossBackward0>)\n",
      "tensor(25.2674, grad_fn=<L1LossBackward0>)\n",
      "tensor(24.1123, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr =[]\n",
    "label = y_noise\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    output = model(x)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = loss_func(output,label)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 ==0:\n",
    "        print(loss)\n",
    "        \n",
    "    #loss_arr.append(loss.cpu().data.numpy()[0])\n",
    "    loss_arr.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.1352],\n",
      "        [-0.6038],\n",
      "        [ 0.0951],\n",
      "        [ 0.6843],\n",
      "        [-0.7918],\n",
      "        [ 0.1031],\n",
      "        [-0.1151],\n",
      "        [-1.1912],\n",
      "        [-0.7675],\n",
      "        [-0.2410],\n",
      "        [-1.3133],\n",
      "        [ 1.4842],\n",
      "        [-0.4947],\n",
      "        [-0.0849],\n",
      "        [ 0.0992],\n",
      "        [-0.8010],\n",
      "        [-0.2533],\n",
      "        [-0.6181],\n",
      "        [-0.2866],\n",
      "        [ 0.9080]], requires_grad=True), Parameter containing:\n",
      "tensor([ 2.6210, -0.8367, -0.9455, -3.4665, -4.2471,  1.4460,  0.6000, -3.5627,\n",
      "        -4.6220, -0.2629, -5.1881,  0.5237, -0.8791,  0.4128,  0.0324, -2.1363,\n",
      "         0.0343, -1.2198,  1.5494, -3.6143], requires_grad=True), Parameter containing:\n",
      "tensor([[ 3.7309e-02, -1.9231e-01,  3.3858e-02,  9.7521e-01, -1.0487e-01,\n",
      "          1.7474e-01,  1.3886e-01, -1.0866e-01,  7.1462e-02, -1.6905e-01,\n",
      "          1.6601e-01,  8.2552e-01,  2.2320e-01, -2.2040e-02,  1.0511e-01,\n",
      "         -4.3289e-02, -1.0368e-01, -5.5975e-02, -2.5536e-02,  1.2129e+00],\n",
      "        [-1.4555e+00, -1.9185e-01, -3.2289e-02,  1.0832e-01,  1.2781e+00,\n",
      "         -7.5986e-01, -3.1002e-01,  5.0804e-01,  1.3652e+00, -6.7884e-03,\n",
      "          1.1491e+00, -2.0411e-01, -5.4753e-02, -9.8538e-02, -1.7524e-01,\n",
      "          2.9323e-01, -5.4359e-01, -2.0492e-02, -5.0674e-01,  1.7918e-01],\n",
      "        [ 2.5197e-01,  2.0911e-01,  6.7820e-02, -9.7735e-01,  5.2473e-01,\n",
      "          2.5543e-01, -3.2007e-01,  2.5156e-01,  2.6865e-01,  2.4088e-01,\n",
      "          4.2690e-01,  5.7219e-01,  3.8592e-01,  1.1684e-02,  1.1195e-01,\n",
      "          2.5266e-01,  1.7836e-01,  1.6327e-01, -1.8842e-01, -8.3337e-01],\n",
      "        [ 4.6106e-01, -2.2059e-01, -5.1410e-02,  4.6922e-01,  8.8184e-02,\n",
      "          4.1244e-01, -1.7254e-01,  9.9724e-02, -2.4098e-02, -1.9672e-01,\n",
      "         -1.5405e-01,  1.6316e+00, -5.3719e-02,  1.6652e-01,  6.0559e-02,\n",
      "          8.3692e-02, -3.1138e-01, -7.6264e-02, -5.1484e-02,  8.3325e-01],\n",
      "        [ 5.6718e-02,  1.1416e-01, -4.2175e-02,  1.6161e-01,  2.0434e-01,\n",
      "         -8.9565e-02,  2.7851e-01,  3.1214e-01,  2.7060e-01,  1.8768e-01,\n",
      "          3.0382e-01, -1.9164e-02,  6.5303e-02,  1.0429e-01, -2.0714e-01,\n",
      "         -6.1531e-02,  2.5315e-01,  3.1288e-01,  6.6410e-02, -3.0876e-03],\n",
      "        [-6.0491e-01, -8.5076e-03, -6.2616e-02,  1.2863e+00,  1.6712e-02,\n",
      "         -1.6305e-02,  7.9403e-02,  5.8161e-02, -3.8587e-02, -1.4098e-01,\n",
      "         -1.2193e-01,  6.8928e-01, -8.6356e-02,  2.3071e-01, -1.6953e-02,\n",
      "         -7.2907e-03, -1.6608e-02,  1.2427e-01, -2.5911e-02,  1.3823e+00],\n",
      "        [-9.6097e-02,  4.3478e-02,  1.1801e-01, -4.9507e-03, -1.0155e-01,\n",
      "          1.5924e-01, -2.5113e-02,  5.7938e-02,  3.3733e-02,  8.8067e-03,\n",
      "         -9.2173e-02,  3.9350e-02, -2.1861e-01, -1.1121e-01, -6.5817e-03,\n",
      "          1.5726e-01,  1.4290e-01,  1.7013e-01, -7.1029e-02, -1.5249e-01],\n",
      "        [-4.2687e-02, -2.2412e-02,  7.0213e-02, -3.5285e-01, -1.8795e-01,\n",
      "          9.0095e-02, -1.2730e-01, -2.0577e-01,  9.4276e-02,  1.9772e-01,\n",
      "          4.1931e-02,  1.0717e-01, -1.9551e-01,  1.8800e-01, -1.8453e-01,\n",
      "          1.5920e-01,  8.1510e-02, -1.1862e-01, -5.8427e-02, -6.7540e-02],\n",
      "        [ 5.1410e-01,  6.0616e-01,  1.2163e-01, -2.2192e+00,  6.8007e-01,\n",
      "          3.6354e-01, -2.7932e-02,  9.3783e-01,  9.5444e-01,  1.8947e-01,\n",
      "          9.4078e-01,  9.0642e-01,  4.1404e-01, -2.2375e-01,  1.4486e-01,\n",
      "          6.0025e-01,  3.1206e-01,  5.9691e-01, -5.6595e-01, -2.1048e+00],\n",
      "        [-8.6371e-01,  1.6702e-01,  6.7091e-02,  1.1318e-01,  8.8102e-01,\n",
      "         -6.9375e-01,  1.6089e-03,  8.7183e-01,  1.2867e+00, -1.1746e-01,\n",
      "          1.2973e+00, -1.1000e-01,  1.4867e-01,  3.5867e-02, -1.6478e-01,\n",
      "          5.6650e-01, -2.9792e-02,  1.7003e-01,  1.7871e-01,  5.6337e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0796, -1.6433, -0.3134,  0.1399, -0.3720, -0.2174, -0.1624, -0.0250,\n",
      "        -0.3784, -1.4440], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.3254, -0.1623, -0.2758,  0.2213, -0.1742, -0.1057,  0.3082, -0.1761,\n",
      "          0.1949, -0.1252],\n",
      "        [ 0.0450,  0.0382,  0.2375,  0.0960, -0.2937, -0.2849, -0.3153,  0.1860,\n",
      "          0.0954, -0.2099],\n",
      "        [-0.2191, -0.0335, -0.2078,  0.0789, -0.0289,  0.0874, -0.1323,  0.0705,\n",
      "          0.0489, -0.0424],\n",
      "        [-0.6363,  2.6184,  1.3154,  0.3823,  0.5933, -1.0387, -0.0623,  0.0730,\n",
      "          2.8975,  2.1549],\n",
      "        [ 1.5783, -0.0804, -0.0195,  2.1305, -0.2018,  1.6520, -0.1717, -0.3307,\n",
      "         -0.5556, -0.2855]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1902, -0.0541, -0.2153, -0.2157, -0.0302], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3106, -0.1459,  0.1870, -4.6610,  3.1274]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3283], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Trained Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "win2=viz.scatter(\n",
    "    X = torch.cat([x, output],1),\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "X and Y should be the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ws/_w1zc2m561d_76233frzs4qr0000gn/T/ipykernel_9317/4144467936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m win3=viz.line(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bigdata/lib/python3.9/site-packages/visdom/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bigdata/lib/python3.9/site-packages/visdom/__init__.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(self, Y, X, win, env, opts, update, name)\u001b[0m\n\u001b[1;32m   1692\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X and Y should be the same shape'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: X and Y should be the same shape"
     ]
    }
   ],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)],newshape=[num_epoch,1])\n",
    "loss_data = np.reshape(loss_arr,newshape=[num_epoch,1])\n",
    "\n",
    "win3=viz.line(\n",
    "    X = x,\n",
    "    Y = loss_data, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
